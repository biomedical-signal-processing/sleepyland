{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Sleep Staging Models\n",
    "\n",
    "---\n",
    "\n",
    "Links to notebooks in this repository:\n",
    "\n",
    "[Quickstart Tutorial](./quickstart_tutorial.ipynb) | [Introduction](../../../../../Downloads/00_introduction.ipynb) | [Services](./01_services.ipynb) | [Sleep Staging](02_sleep_staging.ipynb) | [Ensembling Sleep Staging](./03_ensembling_sleep_staging.ipynb) | [Sleep Dynamics](./04_sleep_dynamics.ipynb) | [Luna Toolbox Integration](./05_luna_integration.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will present how to work with our tutorial EDF files (from the NSRR), as well as how to process your own uploaded data. We will also show how to practically run multiple models in a batch of EDF files you have moved in our shared `input` volume. We’ll use the same helper functions introduced in the previous [Services](./01_services.ipynb) notebook, always following the simple workflowfrom loading data, to harmonizing signal channels, to running predictions and visualizing the results.\n",
    "\n",
    "\n",
    "> Helper function for interacting with the SLEEPYLAND services. By wrapping the HTTP POST logic in one function, we can easily send data/parameters to various endpoints of the `manager-api`, simplifying the code in the rest of the notebook."
   ],
   "id": "2b56213c335aebfb"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define the base URL for the manager-api\n",
    "MANAGER_API_BASE_URL = \"http://manager-api:8989\"\n",
    "\n",
    "def make_post_request(endpoint, data=None, params=None):\n",
    "    \"\"\"\n",
    "    Helper function to make a POST request to the specified endpoint.\n",
    "\n",
    "    Parameters:\n",
    "        endpoint (str): The API endpoint to hit.\n",
    "        data (dict, optional): The form data to send in the request.\n",
    "        params (dict, optional): The URL parameters to send in the request.\n",
    "\n",
    "    Returns:\n",
    "        dict: The JSON response if the request is successful.\n",
    "    \"\"\"\n",
    "    url = f\"{MANAGER_API_BASE_URL}/{endpoint}\"\n",
    "    response = requests.post(url, data=data, params=params)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success:\", response.json())\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed with status code {response.status_code}\")\n",
    "        return None"
   ],
   "id": "5a20ad5e07fceb9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sleep staging on NSRR `learn` data\n",
    "\n",
    "---"
   ],
   "id": "330ca066325d6a27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data loading\n",
    "\n",
    "\n",
    "Let's first relocate the tutorial `.edf` and corresponding `.xml` files from their original exposed path into the shared `../input/learn/` folder. This ensures that all necessary files for the upcoming analyses are consolidated in one place accessible to the pipeline."
   ],
   "id": "6d5421377a68faa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define source and destination directories\n",
    "source_dir = \"../lunapi-notebooks/tutorial/edfs/\"\n",
    "destination_dir = \"../input/learn/\"\n",
    "\n",
    "# Ensure destination directory exists\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of all .edf files in the source directory\n",
    "edf_files = [f for f in os.listdir(source_dir) if f.endswith(\".edf\")]\n",
    "\n",
    "# Copy each .edf file\n",
    "for file in edf_files:\n",
    "    shutil.copy(os.path.join(source_dir, file), destination_dir)\n",
    "\n",
    "xml_files = [f for f in os.listdir(source_dir) if f.endswith(\".xml\")]\n",
    "\n",
    "# Copy each .edf file\n",
    "for file in xml_files:\n",
    "    shutil.copy(os.path.join(source_dir, file), destination_dir)\n",
    "\n",
    "print(f\"Copied {len(edf_files)} EDF files successfully!\")\n",
    "print(f\"Copied {len(xml_files)} XML files successfully!\")"
   ],
   "id": "25aadd4d63e1044a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sleep staging predictions\n",
    "\n",
    "\n",
    "In the block below we first use the get_channels function to determine which signal channels (EEG AND/OR EOG) are available for our `learn` dataset. We then pass those channel selections, along with the dataset name and a list of chosen models (e.g., `yasa` and `usleep`), to the `auto_evaluate_data` function. This automatically harmonizes the data (aligning and preparing signals) and runs sleep-stage predictions for all files in the learn dataset - producing ready-to-use results in the specified output folder (i.e., always retrievable from the `output` volume)."
   ],
   "id": "c5bd12d8f2c723cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_channels(dataset):\n",
    "    \"\"\"\n",
    "    Retrieve the available EEG, EOG, and EMG channels for the specified dataset.\n",
    "    Sends a request to fetch channel information based on the dataset name.\n",
    "\n",
    "    :param dataset: Name of the dataset\n",
    "    :return: Dictionary containing available channels\n",
    "    \"\"\"\n",
    "    params = {'dataset': dataset}\n",
    "    return make_post_request(\"get_channels\", params=params)\n",
    "\n",
    "\n",
    "def auto_evaluate_data(folder_root_name, output_folder_name, eeg_channels, eog_channels, emg_channels, dataset, models):\n",
    "    \"\"\"\n",
    "    Perform both harmonization and prediction using the specified models.\n",
    "\n",
    "    :param folder_root_name: Root folder containing the input data\n",
    "    :param output_folder_name: Folder where results will be saved\n",
    "    :param eeg_channels: List of EEG channels to use\n",
    "    :param eog_channels: List of EOG channels to use\n",
    "    :param emg_channels: List of EMG channels to use\n",
    "    :param dataset: Name of the dataset\n",
    "    :param models: List of models to apply for evaluation\n",
    "    :return: Response from the evaluation request\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'folder_root_name': folder_root_name,\n",
    "        'folder_name': output_folder_name,\n",
    "        'eeg_channels': eeg_channels,\n",
    "        'eog_channels': eog_channels,\n",
    "        'emg_channels': emg_channels,\n",
    "        'dataset': dataset,\n",
    "        'models': models\n",
    "    }\n",
    "    return make_post_request(\"auto_evaluate\", data=data)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title):\n",
    "    \"\"\"\n",
    "    Plot a confusion matrix using Plotly.\n",
    "\n",
    "    :param cm: Confusion matrix as a 2D array\n",
    "    :param labels: List of class labels\n",
    "    :param title: Title of the confusion matrix plot\n",
    "    \"\"\"\n",
    "    fig = ff.create_annotated_heatmap(\n",
    "        z=np.array(cm),\n",
    "        x=labels, y=labels,\n",
    "        colorscale='Blues',\n",
    "        showscale=True\n",
    "    )\n",
    "    fig.update_layout(title=title, xaxis_title='Predicted', yaxis_title='Actual')\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def extract_metrics(data):\n",
    "    \"\"\"\n",
    "    Extract evaluation metrics from the model results.\n",
    "\n",
    "    :param data: List of dictionaries containing model evaluation results\n",
    "    :return: Pandas DataFrame containing extracted metrics\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for model in data:\n",
    "        for model_name, files in model.items():\n",
    "            for file_data in files:\n",
    "                file_name = file_data['file']\n",
    "                metrics = file_data['metrics']\n",
    "                results.append({\n",
    "                    'Model': model_name,\n",
    "                    'File': file_name,\n",
    "                    'Accuracy': metrics['accuracy'],\n",
    "                    'F1 Score': metrics['f1_score'],\n",
    "                    'Cohen Kappa': metrics['cohen_kappa'],\n",
    "                    'Recall': metrics['recall'],\n",
    "                    'Precision': metrics['precision'],\n",
    "                    'Confusion Matrix': metrics['cm']\n",
    "                })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def visualize_results(data):\n",
    "    \"\"\"\n",
    "    Display evaluation results and plot confusion matrices.\n",
    "\n",
    "    :param data: Model evaluation results containing accuracy, precision, recall, etc.\n",
    "    \"\"\"\n",
    "    df_metrics = extract_metrics(data)\n",
    "    print(df_metrics[['Model', 'File', 'Accuracy', 'F1 Score', 'Cohen Kappa', 'Recall', 'Precision']])\n",
    "\n",
    "    # Iterate through the extracted metrics and plot confusion matrices for each model-file combination\n",
    "    for _, row in df_metrics.iterrows():\n",
    "        plot_confusion_matrix(row['Confusion Matrix'], labels=[\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"], title=f\"{row['Model']} - {row['File']}\")\n",
    "\n",
    "\n",
    "# Retrieve the available channels for the dataset\n",
    "# Channels could include EEG and/or EOG derivations depending on the dataset.\n",
    "dataset = 'learn'\n",
    "response = get_channels(dataset)\n",
    "\n",
    "# Extract EEG, EOG, and EMG channels from the response\n",
    "eeg_channels = response[\"eeg_channels\"]\n",
    "eog_channels = response[\"eog_channels\"]\n",
    "emg_channels = ['']  # Empty for now, can be updated as needed\n",
    "\n",
    "# Define the models to be used for evaluation\n",
    "models = ['yasa,usleep']\n",
    "\n",
    "# Perform automatic evaluation using the selected models\n",
    "response = auto_evaluate_data(dataset, 'output_learn', eeg_channels, eog_channels, emg_channels, dataset, models)\n",
    "\n",
    "# Visualize the results from the evaluation\n",
    "visualize_results(response)\n"
   ],
   "id": "94bbd771ca1551d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Hypnograms and hypnodensity graphs\n",
    "\n",
    "Exploit the `create_hypnogram_predict` function to generate simple hypnograms based on the predicted sleep stages from each model. After loading the prediction files from the `output_learn` directory in the `output` volume, we convert the model outputs to stage labels and plot them over time. This helps you quickly visualize how each model classifies sleep stages throughout the night—no ground truth required."
   ],
   "id": "e1d1d027a536eba0"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def create_hypnogram_evaluate(folder_name, models_selected):\n",
    "    \"\"\"\n",
    "    This function compares predicted sleep stages with ground-truth annotations,\n",
    "    plotting both on the same timeline for easy visual evaluation.\n",
    "    \"\"\"\n",
    "    for model in models_selected:\n",
    "        # Paths to the predicted outputs and true labels\n",
    "        majority_folder = os.path.join('..', 'output', folder_name, model, 'majority')\n",
    "        true_folder = os.path.join('..', 'output', folder_name, model, 'TRUE_files')\n",
    "\n",
    "        # Gather the .npy files for predictions and for the ground truth\n",
    "        majority_files = sorted([file for file in os.listdir(majority_folder) if file.endswith('.npy')])\n",
    "        true_files = sorted(os.listdir(true_folder))\n",
    "\n",
    "        for i, (maj_file, true_file) in enumerate(zip(majority_files, true_files)):\n",
    "            # Load model predictions (argmax selects the stage with highest probability)\n",
    "            sleep_stages_majority = np.load(os.path.join(majority_folder, maj_file)).argmax(-1).astype(int)\n",
    "            # Load true labels (already in numeric form)\n",
    "            sleep_stages_true = np.load(os.path.join(true_folder, true_file)).astype(int).ravel()\n",
    "\n",
    "            # Remove threshold limit on printed output (for debugging if needed)\n",
    "            np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "            # Each epoch is 30 seconds, so create a corresponding time axis\n",
    "            time = np.arange(len(sleep_stages_majority)) * 30\n",
    "\n",
    "            # Map numeric labels to textual sleep stage names\n",
    "            sleep_stage_labels = ['Wake', 'NREM1', 'NREM2', 'NREM3', 'REM']\n",
    "            sleep_stages_labels_majority = [sleep_stage_labels[stage] for stage in sleep_stages_majority]\n",
    "            sleep_stages_labels_true = [sleep_stage_labels[stage] for stage in sleep_stages_true]\n",
    "\n",
    "            # Assign colors to each stage index for a visually clear plot\n",
    "            colors = {\n",
    "                0: '#58e306',  # Wake\n",
    "                1: '#2cf7f0',  # NREM1\n",
    "                2: '#1173ef',  # NREM2\n",
    "                3: '#4b4d4d',  # NREM3\n",
    "                4: '#ee0e0e'   # REM\n",
    "            }\n",
    "\n",
    "            # Combine both predicted and true labels in a single figure\n",
    "            fig_combined = go.Figure()\n",
    "\n",
    "            # Plot predicted labels over time\n",
    "            fig_combined.add_trace(go.Scatter(\n",
    "                x=time,\n",
    "                y=sleep_stages_labels_majority,\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='#bdc2c3', width=2, shape='hv'),\n",
    "                marker=dict(size=5, color=[colors[stage] for stage in sleep_stages_majority]),\n",
    "                name='Pred'\n",
    "            ))\n",
    "\n",
    "            # Plot true labels over time\n",
    "            fig_combined.add_trace(go.Scatter(\n",
    "                x=time,\n",
    "                y=sleep_stages_labels_true,\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='#1f77b4', width=2, shape='hv'),\n",
    "                marker=dict(size=5, color=[colors[stage] for stage in sleep_stages_true]),\n",
    "                name='True'\n",
    "            ))\n",
    "\n",
    "            # Configure axes and title for clarity\n",
    "            fig_combined.update_layout(\n",
    "                title=f\"{maj_file.split('.')[0].split('_')[0]} (Pred vs True) - {model}\",\n",
    "                xaxis=dict(title='Time (seconds)'),\n",
    "                yaxis=dict(\n",
    "                    title='Sleep Stage',\n",
    "                    categoryorder='array',\n",
    "                    categoryarray=['NREM3', 'NREM2', 'NREM1', 'REM', 'Wake']\n",
    "                ),\n",
    "                yaxis_range=[-0.5, 4.5]\n",
    "            )\n",
    "\n",
    "            # Display the interactive chart\n",
    "            fig_combined.show()\n",
    "\n",
    "# Call the function to compare predictions with ground truth for both 'usleep' and 'yasa'\n",
    "create_hypnogram_evaluate(\"output_learn\", [\"usleep\", \"yasa\"])"
   ],
   "id": "7ec6660a9b36e6b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_hypnodensity_graph(folder_name, models_selected, is_logits=False):\n",
    "    \"\"\"\n",
    "    Generate a hypnodensity-style graph showing cumulative probability distributions\n",
    "    across all sleep stages for each epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_name (str): Name of the folder containing the output data.\n",
    "        models_selected (list): List of model names to visualize.\n",
    "        is_logits (bool): Flag indicating whether model outputs are raw logits\n",
    "                          (requiring a softmax transform) or already probabilities.\n",
    "    \"\"\"\n",
    "    for model in models_selected:\n",
    "        # Path where prediction data (.npy files) is saved\n",
    "        majority_folder = f'/app/output/{folder_name}/{model}/majority'\n",
    "\n",
    "        # Collect all .npy files for the model from the majority folder\n",
    "        majority_files = sorted([file for file in os.listdir(majority_folder) if file.endswith('.npy')])\n",
    "\n",
    "        for i, maj_file in enumerate(majority_files):\n",
    "            # Load the prediction probabilities (or logits) for each epoch\n",
    "            sleep_probabilities_majority = np.load(os.path.join(majority_folder, maj_file))\n",
    "\n",
    "            # If the model outputs logits, apply softmax here (example usage not shown)\n",
    "            # if is_logits:\n",
    "            #     sleep_probabilities_majority = softmax(sleep_probabilities_majority, axis=1)\n",
    "\n",
    "            # Compute cumulative probabilities over the stages to create \"stacked\" areas\n",
    "            cumulative_probs = np.cumsum(sleep_probabilities_majority, axis=1)\n",
    "\n",
    "            colors = ['#364B9A', '#83B8D7', '#EAECCC', '#F99858', '#A50026']\n",
    "\n",
    "            # Define names for each stage\n",
    "            stage_names = ['Wake', 'N1', 'N2', 'N3', 'REM']\n",
    "\n",
    "            fig = go.Figure()\n",
    "\n",
    "            for j in range(cumulative_probs.shape[1]):\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=np.arange(0, len(cumulative_probs)),\n",
    "                    y=cumulative_probs[:, j],\n",
    "                    mode='lines',\n",
    "                    name=stage_names[j],\n",
    "                    line=dict(width=2, color=colors[j]),  # Set line color\n",
    "                    fill='tonexty',\n",
    "                    fillcolor=f'rgba{tuple(int(colors[j][i:i + 2], 16) for i in (1, 3, 5)) + (0.5,)}',\n",
    "                    # Convert HEX to RGBA\n",
    "                    hoverinfo='none'\n",
    "                ))\n",
    "\n",
    "            # Configure the layout with titles and axis labels\n",
    "            fig.update_layout(\n",
    "                title=f\"{maj_file.split('.')[0].split('_')[0]} - {model}\",\n",
    "                xaxis_title='Time (seconds)',\n",
    "                yaxis_title='Cumulative Probability',\n",
    "                yaxis_range=[0, 1],\n",
    "                showlegend=True\n",
    "            )\n",
    "\n",
    "            # Display the plot\n",
    "            fig.show()\n",
    "\n",
    "# Example call to create hypnodensity graphs for the specified models\n",
    "create_hypnodensity_graph(\"output_learn\", [\"usleep\", \"yasa\"], False)\n"
   ],
   "id": "b3e01029f9eae4e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sleep staging on your own `edf`\n",
    "\n",
    "---\n",
    "\n",
    "In the second part of the notebook, we’ll show how to run SLEEPYLAND’s staging pipeline on your own uploaded `edf` files in few steps - no annotations needed. By following a similar procedure to the tutorial dataset, you can automatically harmonize your recordings, select relevant channels-type (EEG AND/OR EOG), and generate predictions using your model(s) of choice.\n",
    "\n",
    "> NOTE: The system takes in input the channel type the user specify, then it automatically infer and extract all the recognised, e.g., EEG type, channels, forwarding them to the pre-trained models. Thus, the predictions in output are the result of all the combination of EEG AND/OR EOG channels the system recognized from the `edf` file. We suggest to use the majority vote predictions the system give in output."
   ],
   "id": "dc2b247922887d1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Let's first remove/clean all files and subdirectories inside the input volume\n",
    "# Define the directory path where files and folders need to be removed\n",
    "directory = \"/app/input\"\n",
    "\n",
    "# Iterate through all items in the directory\n",
    "for item in os.listdir(directory):\n",
    "    item_path = os.path.join(directory, item)\n",
    "    if os.path.isfile(item_path):\n",
    "        os.remove(item_path)\n",
    "    elif os.path.isdir(item_path):\n",
    "        shutil.rmtree(item_path)"
   ],
   "id": "6afc8681b6b1999f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data loading\n",
    "\n",
    "Below is an example of how to use the `predict_on_my_edf` function with a single EDF file, `learn-nsrr01.edf`. First, we move the file to the shared `input` volume, ensuring that a dataset folder, in that case named `learn` exists (create the folder if necessary). Users should follow the same approach: first, choose/create a preferred root folder name located in the shared input volume, then move all the EDF files they wish to analyze into that folder before running predictions.\n"
   ],
   "id": "6433e98fe8ac8cf3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define source and destination directories\n",
    "source_dir = \"../lunapi-notebooks/tutorial/edfs/\"\n",
    "destination_dir = \"../input/learn/\"\n",
    "\n",
    "# Ensure destination directory exists\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of all .edf files in the source directory\n",
    "edf_files = [f for f in os.listdir(source_dir) if f.endswith(\".edf\")]\n",
    "\n",
    "# Copy one .edf file\n",
    "file_to_copy = edf_files[0]\n",
    "shutil.copy(os.path.join(source_dir, file_to_copy), destination_dir)\n",
    "\n",
    "print(f\"Copied EDF file successfully!\")"
   ],
   "id": "4d8b433d0253fa85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sleep staging predictions\n",
    "\n",
    "> **NOTE** - The exposed endpoint `predict_one` takes as input just **one** EDF file at a time.\n",
    "> Below, we show how to run the prediction on a single EDF file.\n"
   ],
   "id": "e7fd53e74b6f79e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to send prediction request for an EDF file\n",
    "def predict_on_my_edf(folder_root_name, output_folder_name, channels_type, models):\n",
    "    \"\"\"\n",
    "    Sends a request to perform prediction on an EDF file.\n",
    "\n",
    "    Parameters:\n",
    "    folder_root_name (str): Root directory containing the EDF file.\n",
    "    output_folder_name (str): Directory where the prediction results will be saved.\n",
    "    channels_type (list): List of channel types (e.g., EEG, EOG).\n",
    "    models (list): List of models to use for prediction.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'folder_root_name': folder_root_name,\n",
    "        'folder_name': output_folder_name,\n",
    "        'channels': channels_type,\n",
    "        'models': models\n",
    "    }\n",
    "    make_post_request(\"predict_one\", data=data)"
   ],
   "id": "62c5001ec53ff0e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the models to use for prediction\n",
    "models = ['usleep']\n",
    "\n",
    "# Define the channel types to use for prediction\n",
    "channels_type = ['EEG', 'EOG']\n",
    "\n",
    "# Define the dataset name\n",
    "dataset = 'learn'\n",
    "\n",
    "# Use the predict_on_my_edf function to perform prediction on the specified EDF file\n",
    "predict_on_my_edf(dataset, 'output_my_edf', channels_type, models)"
   ],
   "id": "10a205ec55e8f6b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
