{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b56213c335aebfb",
   "metadata": {},
   "source": [
    "# Sleep Staging Models\n",
    "\n",
    "---\n",
    "\n",
    "Links to notebooks in this repository:\n",
    "\n",
    "[Quickstart Tutorial](./quickstart_tutorial.ipynb) | [Introduction](../../../../../Downloads/00_introduction.ipynb) | [Services](./01_services.ipynb) | [Sleep Staging](02_sleep_staging.ipynb) | [Ensembling Sleep Staging](./03_ensembling_sleep_staging.ipynb) | [Sleep Dynamics](./04_sleep_dynamics.ipynb) | [Luna Toolbox Integration](./05_luna_integration.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will present how to work with our tutorial EDF files (from the NSRR), as well as how to process your own uploaded data. We will also show how to practically run multiple models in a batch of EDF files you have moved in our shared `input` volume. Weâ€™ll use the same helper functions introduced in the previous [Services](./01_services.ipynb) notebook, always following the simple workflowfrom loading data, to harmonizing signal channels, to running predictions and visualizing the results.\n",
    "\n",
    "\n",
    "> Helper function for interacting with the SLEEPYLAND services. By wrapping the HTTP POST logic in one function, we can easily send data/parameters to various endpoints of the `manager-api`, simplifying the code in the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a20ad5e07fceb9f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "import yasa\n",
    "\n",
    "# Define the base URL for the manager-api\n",
    "MANAGER_API_BASE_URL = \"http://manager-api:8989\"\n",
    "\n",
    "def make_post_request(endpoint, data=None, params=None):\n",
    "    \"\"\"\n",
    "    Helper function to make a POST request to the specified endpoint.\n",
    "\n",
    "    Parameters:\n",
    "        endpoint (str): The API endpoint to hit.\n",
    "        data (dict): The form data to send in the request.\n",
    "        params (dict): The URL parameters to send in the request.\n",
    "\n",
    "    Returns:\n",
    "        dict: The JSON response if the request is successful.\n",
    "    \"\"\"\n",
    "    url = f\"{MANAGER_API_BASE_URL}/{endpoint}\"\n",
    "    response = requests.post(url, data=data, params=params)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Success:\", response.json())\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed with status code {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330ca066325d6a27",
   "metadata": {},
   "source": [
    "## Sleep staging on NSRR learn dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5421377a68faa5",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "\n",
    "Let's first relocate the tutorial `.edf` and corresponding `.xml` files from their original exposed path into the shared `../input/learn/` folder. This ensures that all necessary files for the upcoming analyses are consolidated in one place accessible to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aadd4d63e1044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source and destination directories\n",
    "source_dir = \"../lunapi-notebooks/tutorial/edfs/\"\n",
    "destination_dir = \"../input/learn/\"\n",
    "\n",
    "# Ensure destination directory exists\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of all .edf files in the source directory\n",
    "edf_files = [f for f in os.listdir(source_dir) if f.endswith(\".edf\")]\n",
    "\n",
    "# Copy each .edf file\n",
    "for file in edf_files:\n",
    "    shutil.copy(os.path.join(source_dir, file), destination_dir)\n",
    "\n",
    "xml_files = [f for f in os.listdir(source_dir) if f.endswith(\".xml\")]\n",
    "\n",
    "# Copy each .edf file\n",
    "for file in xml_files:\n",
    "    shutil.copy(os.path.join(source_dir, file), destination_dir)\n",
    "\n",
    "print(f\"Copied {len(edf_files)} EDF files successfully!\")\n",
    "print(f\"Copied {len(xml_files)} XML files successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd12d8f2c723cf",
   "metadata": {},
   "source": [
    "### Sleep staging predictions\n",
    "\n",
    "\n",
    "In the block below we first use the get_channels function to determine which signal channels (EEG AND/OR EOG) are available for our `learn` dataset. We then pass those channel selections, along with the dataset name and a list of chosen models (e.g., `yasa` and `usleep`), to the `auto_evaluate_data` function. This automatically harmonizes the data (aligning and preparing signals) and runs sleep-stage predictions for all files in the learn dataset - producing ready-to-use results in the specified output folder (i.e., always retrievable from the `output` volume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbd771ca1551d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels(dataset):\n",
    "    \"\"\"\n",
    "    Retrieve the available EEG, EOG, and EMG channels for the specified dataset.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (str): Name of the dataset.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing available channels.\n",
    "    \"\"\"\n",
    "    params = {'dataset': dataset}\n",
    "    return make_post_request(\"get_channels\", params=params)\n",
    "\n",
    "\n",
    "def auto_evaluate_data(folder_root_name, output_folder_name, eeg_channels, eog_channels, emg_channels, dataset, models, resolution):\n",
    "    \"\"\"\n",
    "    Perform both harmonization and evaluation using the specified models.\n",
    "\n",
    "    Parameters:\n",
    "    folder_root_name (str): Root folder containing the input data.\n",
    "    output_folder_name (str): Folder where results will be saved.\n",
    "    eeg_channels (list): List of EEG channels to use.\n",
    "    eog_channels (list): List of EOG channels to use.\n",
    "    emg_channels (list): List of EMG channels to use.\n",
    "    dataset (str): Name of the dataset.\n",
    "    models (list): List of models to apply for evaluation.\n",
    "    resolution (str): Time interval (in seconds) for sleep stage predictions.\n",
    "\n",
    "    Returns:\n",
    "    response (dict): Response from the evaluation request.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'folder_root_name': folder_root_name,\n",
    "        'folder_name': output_folder_name,\n",
    "        'eeg_channels': eeg_channels,\n",
    "        'eog_channels': eog_channels,\n",
    "        'emg_channels': emg_channels,\n",
    "        'dataset': dataset,\n",
    "        'models': models,\n",
    "        'resolution': resolution\n",
    "    }\n",
    "    return make_post_request(\"auto_evaluate\", data=data)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(df_metrics):\n",
    "    \"\"\"\n",
    "    Plot a confusion matrix using Plotly.\n",
    "\n",
    "    Parameters:\n",
    "    df_metrics (pd.DataFrame): DataFrame containing model evaluation\n",
    "    \"\"\"\n",
    "    for _, row in df_metrics.iterrows():\n",
    "        cm = np.array(row['Confusion Matrix'])\n",
    "        order = [0, 1, 2, 3, 4]\n",
    "        cm_reordered = cm[np.ix_(order, order)]\n",
    "        labels = [\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "\n",
    "        text = [[f\"{value:.2f}%\" for value in row] for row in cm_reordered]\n",
    "\n",
    "        fig = go.Figure(data=go.Heatmap(\n",
    "            z=cm_reordered,\n",
    "            x=labels,\n",
    "            y=labels,\n",
    "            colorscale='Blues',\n",
    "            showscale=True,\n",
    "            text=text,\n",
    "            texttemplate=\"%{text}\",\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"{row['Model']} - {row['File']}\",\n",
    "            xaxis_title=\"Predicted Label\",\n",
    "            yaxis_title=\"True Label\",\n",
    "            xaxis=dict(\n",
    "                side='top'\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                autorange='reversed'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "def extract_metrics(data):\n",
    "    \"\"\"\n",
    "    Extract evaluation metrics from the model results.\n",
    "\n",
    "    Parameters:\n",
    "    data (list): List of dictionaries containing model evaluation results.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with separate columns for each F1 score per class.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for model in data:\n",
    "        for model_name, files in model.items():\n",
    "            for file_data in files:\n",
    "                file_name = file_data['file']\n",
    "                metrics = file_data['metrics']\n",
    "\n",
    "                f1_list = metrics.get('f1_score_per_class', [])\n",
    "                \n",
    "                f1_wake = f1_list[0] if len(f1_list) > 0 else None\n",
    "                f1_n1   = f1_list[1] if len(f1_list) > 1 else None\n",
    "                f1_n2   = f1_list[2] if len(f1_list) > 2 else None\n",
    "                f1_n3   = f1_list[3] if len(f1_list) > 3 else None\n",
    "                f1_rem  = f1_list[4] if len(f1_list) > 4 else None\n",
    "\n",
    "                results.append({\n",
    "                    'Model': model_name,\n",
    "                    'File': file_name,\n",
    "                    'Accuracy': metrics['accuracy'],\n",
    "                    'F1 Score': metrics['f1_score'],\n",
    "                    'F1_Wake': f1_wake,\n",
    "                    'F1_N1': f1_n1,\n",
    "                    'F1_N2': f1_n2,\n",
    "                    'F1_N3': f1_n3,\n",
    "                    'F1_REM': f1_rem,\n",
    "                    'Cohen Kappa': metrics['cohen_kappa'],\n",
    "                    'Recall': metrics['recall'],\n",
    "                    'Precision': metrics['precision'],\n",
    "                    'Confusion Matrix': metrics['cm']\n",
    "                })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def visualize_results(data):\n",
    "    \"\"\"\n",
    "    Display evaluation results in a styled DataFrame and\n",
    "    plot confusion matrices.\n",
    "\n",
    "    Parameters:\n",
    "    data (dict): Model evaluation results containing\n",
    "                 accuracy, precision, recall, etc.\n",
    "    \"\"\"\n",
    "    df_metrics = extract_metrics(data)\n",
    "\n",
    "    display(df_metrics.drop(\"Confusion Matrix\", axis=1))\n",
    "    \n",
    "    # Finally, plot confusion matrices\n",
    "    plot_confusion_matrix(df_metrics)\n",
    "\n",
    "\n",
    "# Retrieve the available channels for the dataset\n",
    "# Channels could include EEG and/or EOG derivations depending on the dataset.\n",
    "dataset = 'learn'\n",
    "response = get_channels(dataset)\n",
    "\n",
    "# Extract EEG, EOG, and EMG channels from the response\n",
    "eeg_channels = response[\"eeg_channels\"]\n",
    "eog_channels = response[\"eog_channels\"]\n",
    "emg_channels = ['']  # (not supported yet)\n",
    "\n",
    "# Define the models to be used for evaluation\n",
    "models = ['usleep', 'yasa']\n",
    "\n",
    "# Define the epoch length (in seconds) for each sleep stage prediction - string formatted\n",
    "sec_per_prediction = '30'\n",
    "\n",
    "# Perform automatic evaluation using the selected models\n",
    "response = auto_evaluate_data(dataset, 'output_learn', eeg_channels, eog_channels, emg_channels, dataset, models, sec_per_prediction)\n",
    "\n",
    "# Visualize the results from the evaluation\n",
    "visualize_results(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1d027a536eba0",
   "metadata": {},
   "source": [
    "### Hypnograms and hypnodensity graphs\n",
    "\n",
    "Exploit the `create_hypnogram_predict` function to generate simple hypnograms based on the predicted sleep stages from each model. After loading the prediction files from the `output_learn` directory in the `output` volume, we convert the model outputs to stage labels and plot them over time. This helps you quickly visualize how each model classifies sleep stages throughout the nightâ€”no ground truth required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6660a9b36e6b2",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def create_hypnogram_evaluate(folder_name, models_selected):\n",
    "    \"\"\"\n",
    "    Compare predicted sleep stages with ground-truth annotations,\n",
    "    plotting both on the same timeline for easy visual evaluation.\n",
    "\n",
    "    Parameters:\n",
    "    folder_name (str): The folder containing the model outputs and ground truth data.\n",
    "    models_selected (list): List of models selected for evaluation (e.g., 'usleep', 'yasa').\n",
    "\n",
    "    Returns:\n",
    "    None: The function generates and displays an interactive plot comparing predicted and true sleep stages over time.\n",
    "    \"\"\"\n",
    "    for model in models_selected:\n",
    "        # Paths to the predicted outputs and true labels\n",
    "        majority_folder = os.path.join('..', 'output', folder_name, model, 'majority')\n",
    "        true_folder = os.path.join('..', 'output', folder_name, model, 'TRUE_files')\n",
    "\n",
    "        # Gather the .npy files for predictions and for the ground truth\n",
    "        majority_files = sorted([file for file in os.listdir(majority_folder) if file.endswith('.npy')])\n",
    "        true_files = sorted(os.listdir(true_folder))\n",
    "\n",
    "        for i, (maj_file, true_file) in enumerate(zip(majority_files, true_files)):\n",
    "            # Load model predictions (argmax selects the stage with highest probability)\n",
    "            sleep_stages_majority = np.load(os.path.join(majority_folder, maj_file)).argmax(-1).astype(int)\n",
    "            # Load true labels (already in numeric form)\n",
    "            sleep_stages_true = np.load(os.path.join(true_folder, true_file)).astype(int).ravel()\n",
    "\n",
    "            # Remove threshold limit on printed output (for debugging if needed)\n",
    "            np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "            # Each epoch is 30 seconds, so create a corresponding time axis\n",
    "            time = np.arange(len(sleep_stages_majority))\n",
    "\n",
    "            # Map numeric labels to textual sleep stage names\n",
    "            sleep_stage_labels = ['Wake', 'NREM1', 'NREM2', 'NREM3', 'REM']\n",
    "            sleep_stages_labels_majority = [sleep_stage_labels[stage] for stage in sleep_stages_majority]\n",
    "            sleep_stages_labels_true = [sleep_stage_labels[stage] for stage in sleep_stages_true]\n",
    "\n",
    "            # Assign colors to each stage index for a visually clear plot\n",
    "            colors = {\n",
    "                0: '#58e306',  # Wake\n",
    "                1: '#2cf7f0',  # NREM1\n",
    "                2: '#1173ef',  # NREM2\n",
    "                3: '#4b4d4d',  # NREM3\n",
    "                4: '#ee0e0e'   # REM\n",
    "            }\n",
    "\n",
    "            # Combine both predicted and true labels in a single figure\n",
    "            fig_combined = go.Figure()\n",
    "\n",
    "            # Plot predicted labels over time\n",
    "            fig_combined.add_trace(go.Scatter(\n",
    "                x=time,\n",
    "                y=sleep_stages_labels_majority,\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='#bdc2c3', width=2, shape='hv'),\n",
    "                marker=dict(size=5, color=[colors[stage] for stage in sleep_stages_majority]),\n",
    "                name='Pred'\n",
    "            ))\n",
    "\n",
    "            # Plot true labels over time\n",
    "            fig_combined.add_trace(go.Scatter(\n",
    "                x=time,\n",
    "                y=sleep_stages_labels_true,\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='#1f77b4', width=2, shape='hv'),\n",
    "                marker=dict(size=5, color=[colors[stage] for stage in sleep_stages_true]),\n",
    "                name='True'\n",
    "            ))\n",
    "\n",
    "            # Configure axes and title for clarity\n",
    "            fig_combined.update_layout(\n",
    "                title=f\"{maj_file.split('.')[0].split('_')[0]} (Pred vs True) - {model}\",\n",
    "                xaxis=dict(title='Sleep Epoch'),\n",
    "                yaxis=dict(\n",
    "                    title='Sleep Stage',\n",
    "                    categoryorder='array',\n",
    "                    categoryarray=['NREM3', 'NREM2', 'NREM1', 'REM', 'Wake']\n",
    "                ),\n",
    "                yaxis_range=[-0.5, 4.5]\n",
    "            )\n",
    "\n",
    "            # Display the interactive chart\n",
    "            fig_combined.show()\n",
    "\n",
    "# Call the function to compare predictions with ground truth for both 'usleep' and 'yasa'\n",
    "create_hypnogram_evaluate(\"output_learn\", [\"usleep\", \"yasa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e01029f9eae4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hypnodensity_graph(folder_name, models_selected):\n",
    "    \"\"\"\n",
    "    Generate a hypnodensity-style graph showing cumulative probability distributions\n",
    "    across all sleep stages for each epoch.\n",
    "\n",
    "    Parameters:\n",
    "    folder_name (str): Name of the folder containing the output data.\n",
    "    models_selected (list): List of model names to visualize.\n",
    "\n",
    "    Returns:\n",
    "    None: The function generates and displays an interactive hypnodensity plot for each model.\n",
    "    \"\"\"\n",
    "    for model in models_selected:\n",
    "        # Path where prediction data (.npy files) is saved\n",
    "        majority_folder = f'/app/output/{folder_name}/{model}/majority'\n",
    "\n",
    "        # Collect all .npy files for the model from the majority folder\n",
    "        majority_files = sorted([file for file in os.listdir(majority_folder) if file.endswith('.npy')])\n",
    "\n",
    "        for i, maj_file in enumerate(majority_files):\n",
    "            # Load the prediction probabilities (or logits) for each epoch\n",
    "            sleep_probabilities_majority = np.load(os.path.join(majority_folder, maj_file))\n",
    "\n",
    "            # Compute cumulative probabilities over the stages to create \"stacked\" areas\n",
    "            cumulative_probs = np.cumsum(sleep_probabilities_majority, axis=1)\n",
    "\n",
    "            colors = ['#364B9A', '#83B8D7', '#EAECCC', '#F99858', '#A50026']\n",
    "\n",
    "            # Define names for each stage\n",
    "            stage_names = ['Wake', 'N1', 'N2', 'N3', 'REM']\n",
    "\n",
    "            fig = go.Figure()\n",
    "\n",
    "            for j in range(cumulative_probs.shape[1]):\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=np.arange(0, len(cumulative_probs)),\n",
    "                    y=cumulative_probs[:, j],\n",
    "                    mode='lines',\n",
    "                    name=stage_names[j],\n",
    "                    line=dict(width=0, color=colors[j]),  # Set line color\n",
    "                    fill='tonexty',\n",
    "                    fillcolor=f'rgba{tuple(int(colors[j][i:i + 2], 16) for i in (1, 3, 5)) + (0.5,)}',\n",
    "                    # Convert HEX to RGBA\n",
    "                    hoverinfo='none'\n",
    "                ))\n",
    "\n",
    "            # Configure the layout with titles and axis labels\n",
    "            fig.update_layout(\n",
    "                title=f\"{maj_file.split('.')[0].split('_')[0]} - {model}\",\n",
    "                xaxis_title='Sleep Epoch',\n",
    "                yaxis_title='Cumulative Probability',\n",
    "                yaxis_range=[0, 1],\n",
    "                showlegend=True\n",
    "            )\n",
    "\n",
    "            # Display the plot\n",
    "            fig.show()\n",
    "\n",
    "# Example call to create hypnodensity graphs for the specified models\n",
    "create_hypnodensity_graph(\"output_learn\", [\"usleep\", \"yasa\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0ac42c",
   "metadata": {},
   "source": [
    "### Sleep parameters computation\n",
    "\n",
    "Exploit the `yasa.sleep_statistics` function to quickly compute standard AASM metrics from both predicted and true hypnograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da3c765",
   "metadata": {},
   "source": [
    "Below are the key parameters it returns (with all durations in **minutes**, except for the stage percentages and efficiencies):\n",
    "\n",
    "- Time in Bed (TIB): Total duration of the hypnogram.  \n",
    "- Sleep Period Time (SPT): Duration from the first to the last period of sleep.  \n",
    "- Wake After Sleep Onset (WASO): Total wake time within SPT.  \n",
    "- Total Sleep Time (TST): Now calculated as the sum of all N1 + N2 + N3 + REM in SPT.  \n",
    "- Sleep Efficiency (SE): TST / TIB * 100 (%).\n",
    "- Sleep Maintenance Efficiency (SME): TST / SPT * 100 (%).\n",
    "- W, N1, N2, N3, REM: Duration of each stage (NREM = N1 + N2 + N3).  \n",
    "- Percentages % (W,..., REM): Duration of each stage expressed in % of TST.\n",
    "- Latencies (e.g., `Lat_REM`, `Lat_N1`): Time from the beginning of the recording to the first epoch of each stage.  \n",
    "- Sleep Onset Latency (SOL): Latency to the first epoch of any sleep.  \n",
    "\n",
    "Note that YASAâ€™s REM latency is measured from the start of the record, whereas the AASM definition measures it from the first epoch of sleep. To convert YASAâ€™s `Lat_REM` to the AASM definition, compute `Lat_REM - SOL`.\n",
    "\n",
    "Such a numeric summary provides an instant clinical overview of each modelâ€™s performance relative to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sleep_stats(stats_pred, stats_true, file_name, model_name):\n",
    "    \"\"\"\n",
    "    Given two dictionaries of sleep statistics from YASA (predicted vs. true),\n",
    "    create a grouped bar chart comparing key time-based and percentage metrics.\n",
    "\n",
    "    Parameters:\n",
    "    stats_pred (dict): Dictionary of metrics for the predicted hypnogram.\n",
    "    stats_true (dict): Dictionary of metrics for the ground-truth hypnogram.\n",
    "    file_name (str): Name of the file being analyzed.\n",
    "    model_name (str): Name of the model.\n",
    "\n",
    "    Returns:\n",
    "    None: The function generates and displays a grouped bar chart comparing predicted and true sleep statistics.\n",
    "    \"\"\"\n",
    "    # Define two groups of metrics:\n",
    "    #  - time_metrics are in minutes\n",
    "    #  - percent_metrics are in percentages\n",
    "    time_metrics = [\"TIB\", \"SPT\", \"WASO\", \"TST\", \"N1\", \"N2\", \"N3\", \"REM\", \"NREM\", \"SOL\"] \n",
    "    percent_metrics = [\"%N1\", \"%N2\", \"%N3\", \"%REM\", \"SE\", \"SME\"] \n",
    "    \n",
    "    # Prepare values for each group, using .get() to safely handle missing keys.\n",
    "    pred_time_values = [stats_pred.get(m, np.nan) for m in time_metrics]\n",
    "    true_time_values = [stats_true.get(m, np.nan) for m in time_metrics]\n",
    "\n",
    "    pred_percent_values = [stats_pred.get(m, np.nan) for m in percent_metrics]\n",
    "    true_percent_values = [stats_true.get(m, np.nan) for m in percent_metrics]\n",
    "\n",
    "    # Create a 1-row, 2-column subplot layout\n",
    "    fig = sp.make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=[\"Time Metrics (minutes)\", \"Percentage Metrics\"],\n",
    "        shared_yaxes=False\n",
    "    )\n",
    "\n",
    "    # --- Left subplot: Time Metrics ---\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='Predicted', x=time_metrics, y=pred_time_values, marker_color='steelblue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='True', x=time_metrics, y=true_time_values, marker_color='darkorange'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # --- Right subplot: Percentage Metrics ---\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='Predicted', x=percent_metrics, y=pred_percent_values, marker_color='steelblue'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='True', x=percent_metrics, y=true_percent_values, marker_color='darkorange'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Update the layout for a nice grouped bar appearance\n",
    "    fig.update_layout(\n",
    "        title=f\"Sleep Stats Comparison: {file_name.split(\"_\")[0]} - {model_name}\",\n",
    "        barmode='group',\n",
    "        width=950, height=400,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def compute_sleep_stats(folder_name, models_selected):\n",
    "    \"\"\"\n",
    "    For each model in `models_selected` and each file in `folder_name`,\n",
    "    load the predicted hypnogram and ground-truth labels, then compute\n",
    "    YASA sleep statistics and visualize them in side-by-side bar charts.\n",
    "\n",
    "    Parameters:\n",
    "    folder_name (str): Name of the folder containing the output data.\n",
    "    models_selected (list): List of models to compute and visualize sleep statistics for.\n",
    "\n",
    "    Returns:\n",
    "    None: The function computes YASA sleep statistics and generates plots for each model and file in the specified folder.\n",
    "    \"\"\"\n",
    "    for model in models_selected:\n",
    "        # Paths to the predicted outputs and true labels\n",
    "        majority_folder = os.path.join('..', 'output', folder_name, model, 'majority')\n",
    "        true_folder = os.path.join('..', 'output', folder_name, model, 'TRUE_files')\n",
    "\n",
    "        # Gather .npy files for predictions and ground truth\n",
    "        majority_files = sorted([file for file in os.listdir(majority_folder) if file.endswith('.npy')])\n",
    "        true_files = sorted(os.listdir(true_folder))\n",
    "\n",
    "        for maj_file, true_file in zip(majority_files, true_files):\n",
    "            # Load model predictions (argmax if shape=[n_epochs, n_classes])\n",
    "            sleep_stages_majority = np.load(os.path.join(majority_folder, maj_file)).argmax(-1).astype(int)\n",
    "            # Load true labels (already 1D, numeric)\n",
    "            sleep_stages_true = np.load(os.path.join(true_folder, true_file)).astype(int).ravel()\n",
    "\n",
    "            # Compute YASA stats for predicted & true\n",
    "            sf_hyp = 1 / 30.0  # each epoch = 30 seconds\n",
    "            stats_pred = yasa.sleep_statistics(sleep_stages_majority, sf_hyp)\n",
    "            stats_true = yasa.sleep_statistics(sleep_stages_true, sf_hyp)\n",
    "\n",
    "            # Plot them side-by-side for easier comparison\n",
    "            plot_sleep_stats(stats_pred, stats_true, maj_file, model)\n",
    "\n",
    "            # Optionally, you can still print them if you like:\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"File: {maj_file} | Model: {model}\")\n",
    "            print(\"Predicted Hypnogram Stats:\\n\", stats_pred)\n",
    "            print(\"True Hypnogram Stats:\\n\", stats_true)\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "compute_sleep_stats(\"output_learn\", [\"usleep\", \"yasa\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b247922887d1f",
   "metadata": {},
   "source": [
    "## Sleep staging on your own EDF\n",
    "\n",
    "---\n",
    "\n",
    "In the second part of the notebook, weâ€™ll show how to run SLEEPYLANDâ€™s staging pipeline on your own uploaded `edf` files in few steps - no annotations needed. By following a similar procedure to the tutorial dataset, you can automatically harmonize your recordings, select relevant channels-type (EEG AND/OR EOG), and generate predictions using your model(s) of choice.\n",
    "\n",
    "> NOTE: The system takes in input the channel type the user specify, then it automatically infer and extract all the recognised, e.g., EEG type, channels, forwarding them to the pre-trained models. Thus, the predictions in output are the result of all the combination of EEG AND/OR EOG channels the system recognized from the `edf` file. We suggest to use the majority vote predictions the system give in output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc8681b6b1999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first remove/clean all files and subdirectories inside the input volume\n",
    "# Define the directory path where files and folders need to be removed\n",
    "directory = \"/app/input\"\n",
    "\n",
    "# Iterate through all items in the directory\n",
    "for item in os.listdir(directory):\n",
    "    item_path = os.path.join(directory, item)\n",
    "    if os.path.isfile(item_path):\n",
    "        os.remove(item_path)\n",
    "    elif os.path.isdir(item_path):\n",
    "        shutil.rmtree(item_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6433e98fe8ac8cf3",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "Below is an example of how to use the `predict_on_my_edf` function with a single EDF file, `learn-nsrr01.edf`. First, we move the file to the shared `input` volume, ensuring that a dataset folder, in that case named `learn` exists (create the folder if necessary). Users should follow the same approach: first, choose/create a preferred root folder name located in the shared input volume, then move all the EDF files they wish to analyze into that folder before running predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b433d0253fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source and destination directories\n",
    "source_dir = \"../lunapi-notebooks/tutorial/edfs/\"\n",
    "destination_dir = \"../input/myedf/\"\n",
    "\n",
    "# Ensure destination directory exists\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of all .edf files in the source directory\n",
    "edf_files = [f for f in os.listdir(source_dir) if f.endswith(\".edf\")]\n",
    "\n",
    "edf_files.sort()\n",
    "\n",
    "# Copy one .edf file\n",
    "file_to_copy = edf_files[0]\n",
    "shutil.copy(os.path.join(source_dir, file_to_copy), destination_dir)\n",
    "\n",
    "print(f\"Copied EDF file successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd53e74b6f79e5",
   "metadata": {},
   "source": [
    "### Sleep staging predictions\n",
    "\n",
    "> **NOTE** - The exposed endpoint `predict_one` takes as input just **one** EDF file at a time.\n",
    "> Below, we show how to run the prediction on a single EDF file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5001ec53ff0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send prediction request for an EDF file\n",
    "def predict_on_my_edf(folder_root_name, output_folder_name, channels_type, models, resolution):\n",
    "    \"\"\"\n",
    "    Sends a request to perform prediction on an EDF file.\n",
    "\n",
    "    Parameters:\n",
    "    folder_root_name (str): Root directory containing the EDF file.\n",
    "    output_folder_name (str): Directory where the prediction results will be saved.\n",
    "    channels_type (list): List of channel types (e.g., EEG, EOG).\n",
    "    models (list): List of models to use for prediction.\n",
    "    resolution (str): Time interval (in seconds) for sleep stage predictions\n",
    "\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'folder_root_name': folder_root_name,\n",
    "        'folder_name': output_folder_name,\n",
    "        'channels': channels_type,\n",
    "        'models': models,\n",
    "        'resolution': resolution\n",
    "    }\n",
    "    make_post_request(\"predict_one\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a205ec55e8f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to use for prediction\n",
    "models = ['usleep']\n",
    "\n",
    "# Define the channel types to use for prediction\n",
    "channels_type = ['EEG', 'EOG']\n",
    "\n",
    "# Define the dataset name\n",
    "dataset = 'learn'\n",
    "\n",
    "# Define the epoch length (in seconds) for each sleep stage prediction - string formatted\n",
    "sec_per_prediction = '5'\n",
    "\n",
    "# Use the predict_on_my_edf function to perform prediction on the specified EDF file\n",
    "predict_on_my_edf(dataset, 'output_my_edf', channels_type, models, sec_per_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165c9f7",
   "metadata": {},
   "source": [
    "### Hypnograms and hypnodensity graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0814db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hypnogram_predict(folder_name, models_selected):\n",
    "    \"\"\"\n",
    "    Plot a single hypnogram (predicted stages) for one or more models,\n",
    "    given a folder of .npy prediction files.\n",
    "\n",
    "    Parameters:\n",
    "    folder_name (str): The name of the folder containing the model outputs\n",
    "                       (e.g. 'output_my_edf').\n",
    "    models_selected (list): List of models (e.g. ['usleep']).\n",
    "    epoch_sec (float): Duration (in seconds) of each epoch (default=30).\n",
    "\n",
    "    Returns:\n",
    "    None: This function generates and displays a plot for the predicted hypnogram of each model.\n",
    "    \"\"\"\n",
    "    for model in models_selected:\n",
    "        # Path to the predicted outputs (majority folder)\n",
    "        majority_folder = os.path.join('..', 'output', folder_name, model, 'majority')\n",
    "        \n",
    "        # Gather all .npy files for predictions\n",
    "        majority_files = sorted([file for file in os.listdir(majority_folder)\n",
    "                                 if file.endswith('.npy')])\n",
    "\n",
    "        for maj_file in majority_files:\n",
    "            # Load model predictions\n",
    "            # If shape=[n_epochs, n_classes], take argmax to convert to integer-coded stages\n",
    "            predictions = np.load(os.path.join(majority_folder, maj_file))\n",
    "            if len(predictions.shape) == 2 and predictions.shape[1] > 1:\n",
    "                # Argmax across last dimension if the file contains probabilities/logits\n",
    "                sleep_stages_pred = predictions.argmax(axis=-1).astype(int)\n",
    "            else:\n",
    "                # Already integer-coded or single-class\n",
    "                sleep_stages_pred = predictions.astype(int)\n",
    "\n",
    "            # Create the corresponding time axis\n",
    "            time = np.arange(len(sleep_stages_pred))\n",
    "\n",
    "            # Map numeric labels to textual stage names (0=Wake,1=N1,2=N2,3=N3,4=REM)\n",
    "            stage_names = ['Wake', 'NREM1', 'NREM2', 'NREM3', 'REM']\n",
    "            sleep_stages_labels = [stage_names[st] for st in sleep_stages_pred]\n",
    "\n",
    "            # Define colors for each stage index\n",
    "            colors = {\n",
    "                0: '#58e306',  # Wake\n",
    "                1: '#2cf7f0',  # NREM1\n",
    "                2: '#1173ef',  # NREM2\n",
    "                3: '#4b4d4d',  # NREM3\n",
    "                4: '#ee0e0e'   # REM\n",
    "            }\n",
    "\n",
    "            # Create a single Plotly figure (predictions only)\n",
    "            fig = go.Figure()\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=time,\n",
    "                y=sleep_stages_labels,\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='#bdc2c3', width=2, shape='hv'),\n",
    "                marker=dict(size=5, color=[colors[s] for s in sleep_stages_pred]),\n",
    "                name='Pred'\n",
    "            ))\n",
    "\n",
    "            fig.update_layout(\n",
    "                title=f\"Predicted Hypnogram - {maj_file.split(\"_\")[0]} - {model}\",\n",
    "                xaxis=dict(title='Sleep Epoch'),\n",
    "                yaxis=dict(\n",
    "                    title='Sleep Stage',\n",
    "                    categoryorder='array',\n",
    "                    categoryarray=['NREM3', 'NREM2', 'NREM1', 'REM', 'Wake']\n",
    "                ),\n",
    "                yaxis_range=[-0.5, 4.5]\n",
    "            )\n",
    "            fig.show()\n",
    "\n",
    "\n",
    "create_hypnogram_predict(\"output_my_edf\", [\"usleep\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96164d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hypnodensity_predict(folder_name, models_selected):\n",
    "    \"\"\"\n",
    "    Generate a hypnodensity-style graph showing cumulative probability\n",
    "    distributions across all sleep stages for each epoch (predicted only).\n",
    "\n",
    "    Parameters:\n",
    "    folder_name (str): The folder containing the .npy output data\n",
    "                       (e.g. 'output_my_edf').\n",
    "    models_selected (list): A list of model names (e.g. ['usleep']).\n",
    "\n",
    "    Returns:\n",
    "    None: This function generates and displays a hypnodensity graph for each model's predicted stages.\n",
    "    \"\"\"\n",
    "    for model in models_selected:\n",
    "        majority_folder = os.path.join('..', 'output', folder_name, model, 'majority')\n",
    "        majority_files = sorted([f for f in os.listdir(majority_folder) if f.endswith('.npy')])\n",
    "\n",
    "        for maj_file in majority_files:\n",
    "            # Load the predicted data (probabilities or logits) for each epoch\n",
    "            preds = np.load(os.path.join(majority_folder, maj_file))\n",
    "\n",
    "            # Make sure preds is shape [n_epochs, n_stages]\n",
    "            if len(preds.shape) != 2:\n",
    "                print(f\"Skipping {maj_file}: not in [epochs, stages] format.\")\n",
    "                continue\n",
    "\n",
    "            # Create cumulative probabilities across columns\n",
    "            cumulative_probs = np.cumsum(preds, axis=1)\n",
    "\n",
    "            # Colors for each stage\n",
    "            colors = ['#364B9A', '#83B8D7', '#EAECCC', '#F99858', '#A50026']\n",
    "            stage_names = ['Wake', 'N1', 'N2', 'N3', 'REM']\n",
    "\n",
    "            fig = go.Figure()\n",
    "\n",
    "            # Add stacked areas\n",
    "            for j in range(cumulative_probs.shape[1]):\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=np.arange(len(cumulative_probs)),\n",
    "                    y=cumulative_probs[:, j],\n",
    "                    mode='lines',\n",
    "                    name=stage_names[j],\n",
    "                    line=dict(width=0, color=colors[j]),\n",
    "                    fill='tonexty' if j > 0 else 'none',\n",
    "                    hoverinfo='none'\n",
    "                ))\n",
    "\n",
    "            fig.update_layout(\n",
    "                title=f\"Predicted Hypnodensity Graph: {maj_file.split(\"_\")[0]} - {model}\",\n",
    "                xaxis_title='Sleep Epoch',\n",
    "                yaxis_title='Cumulative Probability',\n",
    "                yaxis_range=[0, 1],\n",
    "                showlegend=True\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "create_hypnodensity_predict(\"output_my_edf\", [\"usleep\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf41422d",
   "metadata": {},
   "source": [
    "### Sleep parameters computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sleep_stats_pred_only(stats_pred, file_name, model_name):\n",
    "    \"\"\"\n",
    "    Create a grouped bar chart for key time-based and percentage metrics,\n",
    "    but only for one predicted dataset (no ground truth available).\n",
    "\n",
    "    Parameters:\n",
    "    stats_pred (dict): YASA metrics for the predicted hypnogram\n",
    "                        (e.g., from `yasa.sleep_statistics`).\n",
    "    file_name (str): Name of the file (e.g., 'myrecord_PRED.npy').\n",
    "    model_name (str): The model name (e.g., 'usleep').\n",
    "\n",
    "    Returns:\n",
    "    None: This function generates and displays a bar chart for the predicted sleep statistics.\n",
    "    \"\"\"\n",
    "    # Metrics to display\n",
    "    time_metrics = [\"TIB\", \"SPT\", \"WASO\", \"TST\", \"N1\", \"N2\", \"N3\", \"REM\", \"NREM\", \"SOL\"]\n",
    "    percent_metrics = [\"%N1\", \"%N2\", \"%N3\", \"%REM\", \"SE\", \"SME\"]\n",
    "\n",
    "    # Extract values, using np.nan for any missing key\n",
    "    pred_time_values = [stats_pred.get(m, np.nan) for m in time_metrics]\n",
    "    pred_percent_values = [stats_pred.get(m, np.nan) for m in percent_metrics]\n",
    "\n",
    "    # Create a 1-row, 2-column layout\n",
    "    fig = sp.make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        subplot_titles=[\"Time Metrics (minutes)\", \"Percentage Metrics\"]\n",
    "    )\n",
    "\n",
    "    # 1) Left subplot: Time Metrics\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name='Predicted',\n",
    "            x=time_metrics,\n",
    "            y=pred_time_values,\n",
    "            marker_color='steelblue'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # 2) Right subplot: Percentage Metrics\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name='Predicted',\n",
    "            x=percent_metrics,\n",
    "            y=pred_percent_values,\n",
    "            marker_color='steelblue'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Remove .npy extension if present\n",
    "    base_name, _ = os.path.splitext(file_name)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Sleep Stats (No Ground Truth): {base_name} - {model_name}\",\n",
    "        barmode='group',\n",
    "        width=950,\n",
    "        height=400\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "def compute_predicted_sleep_stats(folder_name, models_selected, epoch_sec=30):\n",
    "    \"\"\"\n",
    "    For each model in `models_selected` and each .npy file in `folder_name`,\n",
    "    load the predicted hypnogram, compute YASA sleep statistics, and plot them.\n",
    "    \n",
    "    This version handles only predicted data (no true labels).\n",
    "    \n",
    "    Parameters:\n",
    "    folder_name (str): Name of the output folder (e.g. 'output_my_edf').\n",
    "    models_selected (list): List of model names (e.g. ['usleep']).\n",
    "    epoch_sec (float): Duration of each epoch in seconds (default=30).\n",
    "\n",
    "    Returns:\n",
    "    None: This function loads predicted data, computes statistics, and plots them.\n",
    "    \"\"\"\n",
    "    for model in models_selected:\n",
    "        # Path to your predicted outputs (the 'majority' folder)\n",
    "        majority_folder = os.path.join('..', 'output', folder_name, model, 'majority')\n",
    "        \n",
    "        # Collect all .npy files in that folder\n",
    "        majority_files = sorted(f for f in os.listdir(majority_folder) if f.endswith('.npy'))\n",
    "        \n",
    "        for maj_file in majority_files:\n",
    "            # Load the prediction array\n",
    "            pred_array = np.load(os.path.join(majority_folder, maj_file))\n",
    "\n",
    "            # If shape=[epochs, classes], argmax across last dim => integer-coded stages\n",
    "            if pred_array.ndim == 2 and pred_array.shape[1] > 1:\n",
    "                sleep_stages_pred = pred_array.argmax(axis=-1).astype(int)\n",
    "            else:\n",
    "                # Already integer-coded\n",
    "                sleep_stages_pred = pred_array.astype(int)\n",
    "\n",
    "            # Compute YASA stats\n",
    "            sf_hyp = 1.0 / epoch_sec  # e.g., 1/30 = 0.0333 for 30-s epochs\n",
    "            stats_pred = yasa.sleep_statistics(sleep_stages_pred, sf_hyp)\n",
    "\n",
    "            # Plot the stats (predicted only)\n",
    "            plot_sleep_stats_pred_only(stats_pred, maj_file, model)\n",
    "\n",
    "            # Optionally, you can still print them in the console for quick inspection\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"File: {maj_file} | Model: {model}\")\n",
    "            print(\"Predicted Hypnogram Stats:\\n\", stats_pred)\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "compute_predicted_sleep_stats(\"output_my_edf\", [\"usleep\"], epoch_sec=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
